% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ingest.R
\name{ingest_from_local}
\alias{ingest_from_local}
\alias{ingest_from_url}
\alias{ingest_from_blob}
\alias{ingest_from_adls2}
\title{Ingestion functions for Kusto}
\usage{
ingest_from_local(database, src, dest_table, method = NULL,
  ingestion_token = NULL, staging_container = NULL, ...)

ingest_from_url(database, src, dest_table, async = FALSE, ...)

ingest_from_blob(database, src, dest_table, async = FALSE, key = NULL,
  token = NULL, sas = NULL, ...)

ingest_from_adls2(database, src, dest_table, async = FALSE, key = NULL,
  token = NULL, sas = NULL, ...)
}
\arguments{
\item{database}{A Kusto database endpoint object, created with \link{kusto_database_endpoint}.}

\item{src}{The source data. This can be either a data frame, local filename, or URL.}

\item{dest_table}{The name of the destination table.}

\item{method}{For local ingestion, the method to use. See 'Details' below.}

\item{ingestion_token}{For local ingestion, an authentication token for the cluster ingestion endpoint. Only used if \code{method="streaming"}.}

\item{staging_container}{For local ingestion, an Azure Storage container object to use for staging the dataset. Only used if \code{method="indirect"}.}

\item{...}{Named arguments to be treated as ingestion parameters.}

\item{async}{For the URL ingestion functions, whether to do the ingestion asychronously. If TRUE, the function will return immediately while the server handles the operation in the background.}

\item{key, token, sas}{Authentication arguments for the Azure storage ingestion methods. If multiple arguments are supplied, a key takes priority over a token, which takes priority over a SAS. Note that these arguments are for authenticating with the Azure \emph{storage account}, as opposed to Kusto itself.}
}
\description{
Ingestion functions for Kusto
}
\details{
There are up to 3 possible ways to ingest a local dataset, specified by the \code{method} argument.
\itemize{
\item \code{method="indirect"}: The data is uploaded to blob storage, and then ingested from there. This is the default if the AzureStor package is present.
\item \code{method="streaming"}: The data is uploaded to the cluster ingestion endpoint. This is the default if the AzureStor package is not present, however note that currently (February 2019) streaming ingestion has to be explicitly enabled for a cluster by filing a support ticket.
\item \code{method="inline"}: The data is embedded into the command text itself. This is only recommended for testing purposes, or small datasets.
}
}
